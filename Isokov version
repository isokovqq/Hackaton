import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from sklearn.feature_selection import SelectKBest, f_classif
from imblearn.over_sampling import ADASYN
from category_encoders import TargetEncoder
from catboost import CatBoostClassifier, Pool

# Load data
df = pd.read_csv('data/merged_customer_data.csv')

# Drop irrelevant/noisy columns
drop_cols = ['customer_id', 'application_id', 'referral_code', 'random_noise_1', 'previous_zip_code']
df = df.drop(drop_cols, axis=1)

# Feature engineering
# Cap outliers (1.5*IQR rule)
for col in ['annual_income', 'total_debt_amount', 'loan_amount']:
    if col in df.columns:
        Q1, Q3 = df[col].quantile([0.25, 0.75])
        IQR = Q3 - Q1
        df[col] = df[col].clip(lower=Q1 - 1.5*IQR, upper=Q3 + 1.5*IQR)

# Interaction terms
if 'credit_score' in df.columns and 'debt_to_income_ratio' in df.columns:
    df['credit_score_debt_interaction'] = df['credit_score'] * df['debt_to_income_ratio']
if 'num_delinquencies_2yrs' in df.columns and 'credit_utilization' in df.columns:
    df['delinq_credit_util_interaction'] = df['num_delinquencies_2yrs'] * df['credit_utilization']

# Group rare categories
for col in ['state', 'marketing_campaign']:
    if col in df.columns:
        counts = df[col].value_counts()
        rare = counts[counts < 100].index
        df[col] = df[col].apply(lambda x: 'Other' if x in rare else x)

# Drop highly correlated debt features
debt_cols = ['debt_to_income_ratio', 'total_debt_amount', 'monthly_debt_payment', 'debt_service_ratio']
for col1 in debt_cols:
    for col2 in debt_cols:
        if col1 < col2 and col1 in df.columns and col2 in df.columns:
            corr = df[[col1, col2]].corr().iloc[0, 1]
            if abs(corr) > 0.8:
                df = df.drop(col2, axis=1)

# Separate features and target
X = df.drop('default', axis=1)
y = df['default']

# Identify categorical and numeric columns
object_cols = [col for col in X.columns if X[col].dtype == 'object']
cat_cols = object_cols + [col for col in X.columns if X[col].nunique() < 50 and X[col].dtype != 'object']
num_cols = [col for col in X.columns if col not in cat_cols]

# Special handling for num_delinquencies_2yrs if categorical
if 'num_delinquencies_2yrs' in cat_cols:
    cat_cols.remove('num_delinquencies_2yrs')
    cat_cols.append('num_delinquencies_2yrs')
    X['num_delinquencies_2yrs'] = X['num_delinquencies_2yrs'].astype(str)

# Preprocessing pipeline
credit_score_col = 'credit_score' if 'credit_score' in num_cols else None
other_num_cols = [col for col in num_cols if col != credit_score_col]
transformers = [
    ('num', RobustScaler(), other_num_cols),
    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), cat_cols)
]
if credit_score_col:
    transformers.insert(0, ('credit_score', MinMaxScaler(), [credit_score_col]))

preprocessor = ColumnTransformer(transformers=transformers)

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Apply preprocessing
X_train_preprocessed = preprocessor.fit_transform(X_train)
X_test_preprocessed = preprocessor.transform(X_test)

# ADASYN oversampling
adasyn = ADASYN(random_state=42, sampling_strategy=0.5)
X_train_resampled, y_train_resampled = adasyn.fit_resample(X_train_preprocessed, y_train)

# Feature selection (top 25 features)
selector = SelectKBest(score_func=f_classif, k=25)
X_train_selected = selector.fit_transform(X_train_resampled, y_train_resampled)
X_test_selected = selector.transform(X_test_preprocessed)

# Get selected feature names
feature_names = preprocessor.get_feature_names_out()
selected_features = feature_names[selector.get_support()]

# CatBoost with focal loss approximation
model = CatBoostClassifier(
    iterations=1500,
    learning_rate=0.02,
    depth=6,
    l2_leaf_reg=5,
    bagging_temperature=0.5,
    random_strength=1,
    loss_function='Logloss',
    random_seed=42,
    eval_metric='F1',
    verbose=100,
    early_stopping_rounds=100
)

# Grid search
param_grid = {
    'depth': [5, 7],
    'learning_rate': [0.01, 0.02],
    'l2_leaf_reg': [3, 7],
    'bagging_temperature': [0.5, 1.0]
}
grid_search = GridSearchCV(
    estimator=model,
    param_grid=param_grid,
    scoring='f1',
    cv=3,
    verbose=1,
    n_jobs=-1
)
grid_search.fit(X_train_selected, y_train_resampled)

# Best model
model = grid_search.best_estimator_
print("Best Parameters:", grid_search.best_params_)

# Train model
train_pool = Pool(X_train_selected, y_train_resampled)
test_pool = Pool(X_test_selected, y_test)
model.fit(train_pool)

# Predictions
y_pred = model.predict(test_pool)
y_prob = model.predict_proba(test_pool)[:, 1]

# Metrics at default threshold
print("Default Threshold (0.5):")
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Precision:", precision_score(y_test, y_pred))
print("Recall:", recall_score(y_test, y_pred))
print("F1:", f1_score(y_test, y_pred))
print("AUC:", roc_auc_score(y_test, y_prob))

# Optimize threshold for F1
thresholds = np.arange(0.5, 0.9, 0.01)
best_f1 = 0
best_threshold = 0.5
for thresh in thresholds:
    y_pred_thresh = (y_prob > thresh).astype(int)
    f1 = f1_score(y_test, y_pred_thresh)
    if f1 > best_f1:
        best_f1 = f1
        best_threshold = thresh

# Metrics with best threshold
y_pred_best = (y_prob > best_threshold).astype(int)
print(f"\nBest Threshold ({best_threshold}):")
print("Accuracy:", accuracy_score(y_test, y_pred_best))
print("Precision:", precision_score(y_test, y_pred_best))
print("Recall:", recall_score(y_test, y_pred_best))
print("F1:", f1_score(y_test, y_pred_best))
print("AUC:", roc_auc_score(y_test, y_prob))

# Feature importance
importances = model.get_feature_importance()
for feat, imp in zip(selected_features, importances):
    print(f"Feature: {feat}, Importance: {imp}")

# Cross-validation
from sklearn.model_selection import cross_val_score
from sklearn.metrics import make_scorer
cv_scores = cross_val_score(model, X_train_selected, y_train_resampled, cv=5, scoring=make_scorer(f1_score))
print("Cross-validated F1:", cv_scores.mean(), "+/-", cv_scores.std())
